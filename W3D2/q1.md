Q: 1
üîß Problem 1: Model Comparison and Use-case Mapping
Build a command-line tool that helps users compare Base, Instruct, and Fine-tuned models from popular providers (OpenAI, Anthropic, Hugging Face). The tool should:

Allow users to input a query and choose a model type.
Call the appropriate API or use a locally downloaded model to generate a response.
Output the result along with a brief summary of the model‚Äôs characteristics (e.g., fine-tuning strategy, instruction-following capabilities).
Optional: Support visualization of token usage and context window length in the output.
üß† Key Concepts:
Base vs Instruct vs Fine-tuned, Tokenization, Model APIs, Prompt Engineering

üìù Submission Guidelines:
Push code to a public GitHub repo with a clear README.md explaining how to run it.
Include a comparisons.md document with:
Summary table of model outputs for at least 5 diverse prompts
Commentary on when each model type is more appropriate
Include sample .env.example or config files for API keys.
